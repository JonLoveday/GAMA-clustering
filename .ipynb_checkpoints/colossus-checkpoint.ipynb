{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colossus examples\n",
    "\n",
    "Based on https://bdiemer.bitbucket.io/colossus/_static/tutorial_cosmology.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mpmath\n",
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.special\n",
    "import scipy.stats\n",
    "from colossus.cosmology import cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 & 2 Maximum likelihood example: exponential decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1a)  We need to show that the PDF is correctly normalised.\n",
    "  \\begin{equation}\n",
    "    \\int_0^\\infty p(t) = \\frac{1}{\\tau} \\int_0^\\infty e^{-t/\\tau} =\n",
    "    \\frac{1}{\\tau} \\left[ -\\tau e^{-t/\\tau}\\right]_0^\\infty = 1,\n",
    "  \\end{equation}\n",
    "  as required.\n",
    "\n",
    "  Deriving estimates for $\\tau$ and its variance:\n",
    "\\begin{align*}\n",
    "p(t) &= \\frac{1}{\\tau}e^{-t/\\tau}\\\\\n",
    "{\\cal L} &= \\prod_i \\frac{1}{\\tau}e^{-t_i/\\tau}\\\\\n",
    "l &= -N \\ln \\tau - \\sum_i t_i/\\tau\\\\\n",
    "l' &= \\frac{-N}{\\tau} + \\sum_i t_i/\\tau^2 = 0 \\Rightarrow \n",
    "\\widehat\\tau = \\frac{1}{N} \\sum_i t_i\\\\\n",
    "l'' &= \\frac{N}{\\tau^2} - \\sum_i 2 t_i/\\tau^3\\\\\n",
    "\\langle l'' \\rangle &= \\frac{N}{\\tau^2} - \\frac{2N \\tau}{\\tau^3} = \n",
    "\\frac{-N}{\\tau^2}\\\\\n",
    "V(\\tau) & = \\frac{1}{\\langle -l'' \\rangle} = \\frac{\\widehat{\\tau}^2}{N}.\n",
    "\\end{align*}\n",
    "\n",
    "(1b) The log likelihood $l(\\tau)$ is now given by\n",
    "\\begin{equation}\n",
    "l(\\tau) = \\sum \\left[-\\ln \\tau - \\frac{t_i}{\\tau} - \\ln(1 -  e^{-T/\\tau}) \\right].\n",
    "\\end{equation}\n",
    "\n",
    "Differentiating the log likelihood $l$ and setting it to zero gives \n",
    "\\begin{align*}\n",
    "\\frac{dl}{d \\tau} & = -\\frac{N}{\\tau} + \\sum t_i/\\tau^2 - \n",
    "\\frac{N}{1 -  e^{-T/\\tau}}. -e^{-T/\\tau}.\\frac{T}{\\tau^2}\\\\\n",
    "& = -\\frac{N}{\\tau} + \\sum t_i/\\tau^2 +\n",
    "\\frac{NT}{\\tau^2} \\frac{e^{-T/\\tau}}{1 -  e^{-T/\\tau}}\\\\\n",
    "\\tau^2 \\frac{dl}{d \\tau} & = -N \\tau + \\sum t_i + NT \\frac{e^{-T/\\tau}}{1 -  e^{-T/\\tau}} = 0.\n",
    "\\end{align*}\n",
    "\n",
    "Hence our maximum likelihood estimate is given by\n",
    "\\begin{equation}\n",
    "\\widehat{\\tau }=\\frac{1}{N}\\sum t_{i}+ \\frac{Te^{-T/\\widehat{%\n",
    "\\tau }}}{\\left( 1-e^{-T/\\widehat{\\tau }}\\right) }.\n",
    "\\end{equation}\n",
    "\n",
    "(1c)\n",
    "  Use the transformation method to generate exponentially distributed\n",
    "  random numbers $t$ from a uniform distribution $x$:\n",
    "\\begin{align*}\n",
    "  x &= \\int_0^t dt \\frac{1}{\\tau} e^{-t/\\tau} = \\left[-e^{-t/\\tau}\\right]_0^t\n",
    "      = 1 - e^{-t/\\tau}\\\\\n",
    "  t &= -\\tau \\ln(1-x).\n",
    "\\end{align*}\n",
    "Alternatively, use np.random.exponential().\n",
    "  Then select times $t < T$.\n",
    "\n",
    "(1d) Estimated $\\tau$ should be consistent with true value.  Note in particular\n",
    "  that a simple mean of the generated times grossly underestimates $\\tau$.\n",
    "\n",
    "(2) We simply multiply the likelihood from the new observations by the\n",
    "  prior probability, which, assuming Gaussian errors, is given by:\n",
    "  \\begin{align*}\n",
    "    P_{\\rm prior}(\\tau) &= \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\n",
    "                         e^{-(\\tau - \\tau_P)^2/2 \\sigma^2},\\\\\n",
    "   {\\cal L} &= P_{\\rm prior}(\\tau) \\prod_i\n",
    "              \\frac{1}{\\tau }e^{-t/\\tau}\\left( 1-e^{-T/\\tau }\\right) ^{-1},\\\\\n",
    "    l &= -\\ln(\\sqrt{2 \\pi \\sigma^2}) - \\frac{(\\tau - \\tau_P)^2}{2 \\sigma^2}\n",
    "        + \\sum_i  \\left[-\\ln \\tau - \\frac{t_i}{\\tau} - \\ln(1 -  e^{-T/\\tau}) \\right].\n",
    "  \\end{align*}\n",
    "\n",
    "  Differentiating the log likelihood $l$ and setting it to zero gives \n",
    "  \\begin{align*}\n",
    "    \\frac{dl}{d \\tau} & = -\\frac{\\tau - \\tau_P}{\\sigma^2}\n",
    "                        - \\frac{N}{\\tau} + \\sum t_i/\\tau^2 +\n",
    "                        \\frac{NT}{\\tau^2} \\frac{e^{-T/\\tau}}{1 -  e^{-T/\\tau}}\\\\\n",
    "        \\tau^2 \\frac{dl}{d \\tau} & = -\\frac{(\\tau - \\tau_P)\\tau^2}{\\sigma^2} -\n",
    "                               N \\tau + \\sum t_i +\n",
    "                               NT \\frac{e^{-T/\\tau}}{1 -  e^{-T/\\tau}} = 0.\n",
    "\\end{align*}\n",
    "\n",
    "Hence our maximum likelihood estimate is given by\n",
    "\\begin{equation}\n",
    "\\widehat{\\tau }=\\frac{1}{N}\\sum t_{i}+ \\frac{Te^{-T/\\widehat{%\n",
    "      \\tau }}}{\\left( 1-e^{-T/\\widehat{\\tau }}\\right) } -\n",
    "\\frac{1}{N} \\frac{(\\tau - \\tau_P)\\tau^2}{\\sigma^2}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_trunc(nran=1000, tau=10, T=15, tau_p=8, sigma=1):\n",
    "    \"\"\"Truncated exponential distribution.\"\"\"\n",
    "    t = np.random.exponential(tau, nran)\n",
    "    t = t[t < T]\n",
    "    tt = -tau*np.log(1 - np.random.random(nran))\n",
    "    tt = tt[tt < T]\n",
    "    nuse = len(t)\n",
    "    plt.clf()\n",
    "    plt.hist(t, 15)\n",
    "#    plt.hist(tt, 15)\n",
    "    plt.xlabel('t [s]')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    tmean = t.mean()\n",
    "\n",
    "    def fn(te):\n",
    "        return tmean + T*math.exp(-T/te) / (1 - math.exp(-T/te)) - te\n",
    "\n",
    "    def fn_prior(te):\n",
    "        return (tmean + T*math.exp(-T/te) / (1 - math.exp(-T/te))\n",
    "                - (te - tau_p)*te**2 / (nuse*sigma**2) - te)\n",
    "\n",
    "    res = scipy.optimize.fsolve(fn, tmean)\n",
    "    print('tmean = {:4.1f}, maxL solution = {:4.1f}, est std = {:4.1f}'.format(\n",
    "            tmean, res[0], res[0]/math.sqrt(nuse)))\n",
    "    res = scipy.optimize.fsolve(fn_prior, tmean)\n",
    "    print('With prior maxL solution = {:4.1f}, est std = {:4.1f}'.format(\n",
    "            res[0], res[0]/math.sqrt(nuse)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try calling exp_trunc with different values of N.  \n",
    "# For low N, you should find that the estimate is pulled down by the prior, \n",
    "# but as N increases, the estimate should tend to the 'true' value.\n",
    "exp_trunc(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Bayesâ€™ theorem example 2: constrained measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  For measurement $x$ and theory $X$, Bayes' theorem states\n",
    "  \\begin{equation}\n",
    "    p(X|x) = \\frac{p(x|X) p(X)}{p(x)}.\n",
    "  \\end{equation}\n",
    "\n",
    "  For Gaussian measurement errors and a constant prior for positive $X$,\n",
    "  we have:\n",
    "  \\begin{align*}\n",
    "    p(x|X) &= \\frac{e^{-(x-X)^2/2\\sigma^2}}{\\sigma \\sqrt{2 \\pi}},\\\\\n",
    "    p(X) &= \\mbox{ const if } X > 0, \\mbox{ zero otherwise},\\\\\n",
    "    p(x) &= \\int_{-\\infty}^\\infty p(x|X) p(X) dX = \\int_0^\\infty p(x|X) dX.\n",
    "  \\end{align*}\n",
    "  We thus have\n",
    "\\begin{equation}\n",
    "p\\left( X|x\\right) =\\frac{e^{-\\left( x-X\\right) ^{2}/2\\sigma ^{2}}}\n",
    "{\\int_{0}^{\\infty }e^{-( x-X) ^{2}/2\\sigma^{2}}dX}\n",
    "\\mbox{ for $X > 0$, zero otherwise.}\n",
    "\\end{equation}\n",
    "\n",
    "Now, substituting $y = (x - X)/\\sqrt{2} \\sigma$,\n",
    "\\begin{equation}\n",
    "\\int_{0}^{\\infty }e^{-( x-X) ^{2}/2\\sigma^{2}}dX =\n",
    "\\sqrt{2} \\sigma \\int_{-x/\\sqrt{2} \\sigma}^\\infty e^{-y^2} dy =\n",
    "\\sqrt{2} \\sigma \\frac{\\sqrt{\\pi}}{2} {\\rm erfc} (-x/\\sqrt{2} \\sigma),\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "{\\rm erfc}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_x^\\infty e^{-t^2} dt.\n",
    "\\end{equation}\n",
    "\n",
    "Thus\n",
    "\\begin{equation}\n",
    "p(X|x) =\\sqrt{\\frac{2}{\\pi}} \\frac{1}{\\sigma} \\frac{e^{-\\left( x-X\\right) ^{2}/2\\sigma ^{2}}}\n",
    "{{\\rm erfc} (-x/\\sqrt{2} \\sigma)}\n",
    "\\mbox{ for $X > 0$, zero otherwise.}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes(sigma=0.2, X=np.linspace(0.001, 1.0, 50)):\n",
    "    \"\"\"Bayesian limits on mass (Q3)\"\"\"\n",
    "\n",
    "    def p(X, x, sigma):\n",
    "        prob = np.zeros(len(X))\n",
    "        idx = X > 0\n",
    "        prob[idx] = (np.sqrt(2.0/math.pi) / sigma * np.exp(-(x - X[idx])**2/(2 * sigma**2))/\n",
    "                     scipy.special.erfc(-x/(np.sqrt(2.0) * sigma)))\n",
    "        return prob\n",
    "\n",
    "    plt.clf()\n",
    "    for x in (-0.3, -0.1, 0.1, 0.3):\n",
    "        plt.plot(X, p(X, x, sigma), label='x = {}'.format(x))\n",
    "    plt.xlabel(r'$X$')\n",
    "    plt.ylabel(r'$P(X|x)$')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Generating arbitrarily distributed random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ran_dist(x, p, nran):\n",
    "    \"\"\"Generate nran random points according to distribution p(x)\"\"\"\n",
    "\n",
    "    if np.amin(p) < 0:\n",
    "        print('ran_dist warning: pdf contains negative values!')\n",
    "    cp = np.cumsum(p)\n",
    "    y = (cp - cp[0]) / (cp[-1] - cp[0])\n",
    "    r = np.random.random(nran)\n",
    "    return np.interp(r, y, x)\n",
    "\n",
    "\n",
    "def ran_fun(f, xmin, xmax, nran, args=None, nbin=1000):\n",
    "    \"\"\"Generate nran random points according to pdf f(x)\"\"\"\n",
    "\n",
    "    x = np.linspace(xmin, xmax, nbin)\n",
    "    if args:\n",
    "        p = f(x, *args)\n",
    "    else:\n",
    "        p = f(x)\n",
    "    return ran_dist(x, p, nran)\n",
    "\n",
    "\n",
    "def ran_fun2(f, xmin, xmax, ymin, ymax, nran, args=(), nbin=1000, pplot=False):\n",
    "    \"\"\"Generate nran random points according to 2d pdf f(x,y)\"\"\"\n",
    "\n",
    "    dx = float(xmax - xmin)/nbin\n",
    "    dy = float(ymax - ymin)/nbin\n",
    "    x = np.linspace(xmin + 0.5*dx, xmax - 0.5*dx, nbin)\n",
    "    y = np.linspace(ymin + 0.5*dy, ymax - 0.5*dy, nbin)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    p = f(xv, yv, *args)\n",
    "    if pplot:\n",
    "        plt.clf()\n",
    "        plt.imshow(p, aspect='auto', origin='lower',\n",
    "                   extent=(xmin, xmax, ymin, ymax), interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "    binno = range(nbin * nbin)\n",
    "    bins = (ran_dist(binno, p, nran)).astype(int)\n",
    "    j = bins // nbin\n",
    "    i = bins % nbin\n",
    "    xran = x[i]\n",
    "    yran = y[j]\n",
    "\n",
    "    # Add uniform random offsets to avoid quantization\n",
    "    xoff = dx * (np.random.random(nran) - 0.5)\n",
    "    yoff = dy * (np.random.random(nran) - 0.5)\n",
    "\n",
    "    return xran + xoff, yran + yoff\n",
    "\n",
    "\n",
    "def ran_fun_test():\n",
    "    \"\"\"Test ran_fun2\"\"\"\n",
    "\n",
    "    def fun(x, y):\n",
    "        return np.cos(x)**2 * np.sin(y)**2\n",
    "\n",
    "    xr, yr = ran_fun2(fun, -5, 5, -5, 5, 10000, pplot=True)\n",
    "    plt.scatter(xr, yr, 0.1, c='w')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ran_fun_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q6 MCMC example: galaxy stellar mass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsmf_sim(N=1000, lgmstar=10.66, alpha=-1.1,\n",
    "             lgm_min=8, lgm_max=11.5, nchain=3, nstep=1000):\n",
    "    \"\"\"Simulation and fitting of galaxy stellar mass function (single Schecter function).\"\"\"\n",
    "\n",
    "    ln2pi = math.log(2*math.pi)\n",
    "\n",
    "    def schec(lgm, lgmstar, alpha):\n",
    "        \"\"\"Schechter function in log mass.\"\"\"\n",
    "        mr = 10**(lgm - lgmstar)\n",
    "        phi = np.exp(-mr) * mr**(alpha+1)\n",
    "        return phi\n",
    "    \n",
    "    def lnprob(theta):\n",
    "        lgmstar = theta[0]\n",
    "        alpha = theta[1]\n",
    "#        prior = (scipy.stats.norm.pdf(theta[0], loc=10.66, scale=2) *\n",
    "#                 scipy.stats.norm.pdf(theta[1], loc=-1.1, scale=2))\n",
    "#        if prior < 1e-20:\n",
    "#            return -math.inf\n",
    "        # Normalise the pdf\n",
    "        res = scipy.integrate.quad(schec, lgm_min, lgm_max, args=(lgmstar, alpha))\n",
    "        mr = 10**(lgm - lgmstar)\n",
    "        ll = np.sum(-mr + np.log(mr**(alpha+1))) - len(mr)*math.log(res[0])  #  + np.log(prior)\n",
    "#        print(theta, ll)\n",
    "        return ll\n",
    "\n",
    "    lgm = ran_fun(schec, lgm_min, lgm_max, N, args=(lgmstar, alpha), nbin=1000)\n",
    "    plt.clf()\n",
    "    plt.hist(lgm, 50)\n",
    "#    plt.loglog(basex=10, basey=10, nonposy='clip')\n",
    "    plt.semilogy(basey=10, nonposy='clip')\n",
    "    plt.xlabel('lg Mass')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    ndim = 2\n",
    "    x0 = (11, -1)\n",
    "#    print(lnprob(x0))\n",
    "    nwalkers = 10*ndim\n",
    "    pos = np.tile(x0, (nwalkers, 1)) + 0.1*np.random.randn(nwalkers, ndim)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob)\n",
    "    for ichain in range(nchain):\n",
    "        sampler.reset()\n",
    "        pos, prob, state = sampler.run_mcmc(pos, nstep)\n",
    "        print(\"Mean acceptance fraction: {0:.3f}\"\n",
    "              .format(np.mean(sampler.acceptance_fraction)))\n",
    "        try:\n",
    "            print(\"Autocorrelation time:\", sampler.get_autocorr_time(c=1))\n",
    "        except:\n",
    "            print(\"Unable to compute autocorrelation time\")\n",
    "        plt.clf()\n",
    "        nrow = 2\n",
    "        ncol = 1\n",
    "        fig, axes = plt.subplots(nrow, ncol, num=1)\n",
    "        fig.subplots_adjust(hspace=0, wspace=0.1)\n",
    "        fig.text(0.5, 0.02, 'Step number', ha='center', va='center')\n",
    "        fig.text(0.06, 0.75, r'$\\lg M^*$', ha='center',\n",
    "                 va='center', rotation='vertical')\n",
    "        fig.text(0.06, 0.25, r'$\\alpha$', ha='center',\n",
    "                 va='center', rotation='vertical')\n",
    "        for ipar in range(ndim):\n",
    "            ax = axes[ipar]\n",
    "            for iw in range(nwalkers):\n",
    "                ax.plot(sampler.chain[iw, :, ipar])\n",
    "#                if (iw == 0):\n",
    "#                    print(sampler.chain[iw, :, ipar])\n",
    "        plt.show()\n",
    "    res = np.array(np.percentile(sampler.flatchain, [50, 16, 84], axis=0))\n",
    "    print(res)\n",
    "    samples = sampler.chain.reshape((-1, ndim))\n",
    "    fig = corner.corner(samples, labels=[\"lg M*\", \"alpha\"],\n",
    "                        truths=[lgmstar, alpha])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsmf_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Model selection\n",
    "We generate data from an N'th degree polynomial, add random noise, and then try to recover original polynomial order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polydata(ord=4, xmin=0, xmax=1, ndat=21, sigma=0.1):\n",
    "    \"\"\"Generate data points from a polynomial.\"\"\"\n",
    "    c = np.random.rand(ord+1)\n",
    "    print(c)\n",
    "    x = np.linspace(xmin, xmax, ndat)\n",
    "    y = np.polynomial.polynomial.polyval(x, c) + sigma*np.random.randn(ndat)\n",
    "    plt.clf()\n",
    "    plt.errorbar(x,y, sigma)\n",
    "    plt.show()\n",
    "    np.savetxt('polydat.txt', (x, y))\n",
    "\n",
    "#polydata() - don't run. this again!!\n",
    "# Poly coeffs actually used: [ 0.76886506  0.49652911  0.25102958  0.99192304  0.58602027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit(sigma=0.1):\n",
    "    x, y = np.loadtxt('polydat.txt')\n",
    "    print('deg, chisq, chisq prob, aic, bic')\n",
    "    for deg in range(10):\n",
    "        k = deg + 1  # no of parameters\n",
    "        nu = len(x) - k\n",
    "        cfit = np.polynomial.polynomial.polyfit(x, y, deg, w=sigma*np.ones(len(x)))\n",
    "        ygen = np.polynomial.polynomial.polyval(x, cfit)\n",
    "        chisq = np.sum((ygen - y)**2)/0.1**2\n",
    "        prob = 1 - scipy.stats.chi2.cdf(chisq, nu)\n",
    "        aic = 2*k + chisq\n",
    "        bic = np.log(len(x))*k + chisq\n",
    "        print(deg, chisq, prob, aic, bic)\n",
    "polyfit()\n",
    "# Note that deg=3 polynomial is slightly preferred over actual deg=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
